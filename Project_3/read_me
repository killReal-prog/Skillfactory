Список вещей, которые надо прояснить:

Стоит ли увеличивать количество признаков, потому что их можно сделать реально очень много. В чужих работах видел 700+ признаков. При этом МАЕ у них был лучше.

Имеют ли одни признаки большую значимость чем другие? Судя по всему да. То есть влияние признаков взвешено как я понял. Тогда почему иногда нужно наоборот уменьшать количество признаков? Они ведь тоже несут информацию. В чужой работе видел, что снижение количества кухонь до 30 снижает МАЕ. 

Как в принципе работает ForestRegression? Или нам пока рано это знать. Правильно ли я понимаю что для каждый алгоритм работает по-своему и их надо кормить разными данными?

Я попробовал сделать нормализацию признаков и получил в итоге МАЕ на 0.1 больше. Мб сделал неправильно, но вроде все выглядело как надо. Может ли такое быть? Я думал что нормализация всегда улучшает линейные алгоритмы. 

Как с помощью feature selection сделать перебор всех возможных сочетаний признаков для выбора лучшего сочетания? Нашел только как сделать выбор n-количества самых влиятельных признаков а интересует немного другое, потому что как я понял комбинации признаков могут дать неожиданные результаты.

МАЕ в каггле меньше, потому что там обучающая выборка на 10000 больше?

Не очень понял, какие выводы можно было сделать из распределения и корреляции признаков. Этот момент если честно плохо проработал.

В вебинаре говорили, что при обработке ценовых категорий не важно как мы их закодируем, главное что их можно сравнить(больше/меньше). То есть не важно (1,2,3) или (1,2,500)? Это к вопросу о взвешенности признаков и работе алгоритма.

